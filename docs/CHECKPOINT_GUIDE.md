# Checkpoint & Resume Training Guide

## –°—Ö–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ç–æ—á–µ–∫ –æ–±—É—á–µ–Ω–∏—è

### 1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ Checkpoints

–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç:

#### **XGBoost:**
```
models/bpm_correctors/checkpoints/
‚îú‚îÄ‚îÄ xgboost_epoch_100_20250123_103045.pkl
‚îú‚îÄ‚îÄ xgboost_epoch_200_20250123_104012.pkl
‚îú‚îÄ‚îÄ xgboost_epoch_300_20250123_104938.pkl  ‚Üê —Ñ–∏–Ω–∞–ª—å–Ω–∞—è
‚îú‚îÄ‚îÄ checkpoint_metadata.json
‚îú‚îÄ‚îÄ training_history.json
‚îî‚îÄ‚îÄ features.pkl  ‚Üê –∫—ç—à —Ñ–∏—á–µ–π (–æ–¥–∏–Ω —Ä–∞–∑)
```

**–ß–∞—Å—Ç–æ—Ç–∞:** –∫–∞–∂–¥—ã–µ 100 –¥–µ—Ä–µ–≤—å–µ–≤ (n_estimators)

#### **Neural Network:**
```
models/bpm_correctors/checkpoints/
‚îú‚îÄ‚îÄ neural_network_epoch_20_20250123_110521.pkl
‚îú‚îÄ‚îÄ neural_network_epoch_40_20250123_111205.pkl
‚îú‚îÄ‚îÄ neural_network_epoch_60_20250123_111849.pkl
‚îú‚îÄ‚îÄ neural_network_best.pkl  ‚Üê –ª—É—á—à–∞—è –ø–æ val_loss
‚îî‚îÄ‚îÄ ...
```

**–ß–∞—Å—Ç–æ—Ç–∞:** –∫–∞–∂–¥—ã–µ 20 —ç–ø–æ—Ö + –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (EarlyStopping)

---

### 2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ Checkpoint

#### checkpoint_metadata.json
```json
{
  "xgboost_epoch_300_20250123": {
    "epoch": 300,
    "algorithm": "xgboost",
    "metrics": {
      "train_mae": 1.85,
      "val_mae": 1.92
    },
    "timestamp": "20250123_104938",
    "model_path": "models/.../xgboost_epoch_300_20250123.pkl"
  },
  "neural_network_epoch_60_20250123": {
    "epoch": 60,
    "algorithm": "neural_network",
    "metrics": {
      "train_loss": 1.23,
      "val_loss": 1.31
    },
    "timestamp": "20250123_111849",
    "model_path": "models/.../neural_network_epoch_60_20250123.pkl"
  }
}
```

#### training_history.json
```json
{
  "xgboost": {
    "epochs": [100, 200, 300],
    "metrics": {
      "train_mae": [2.15, 1.98, 1.85],
      "val_mae": [2.21, 2.05, 1.92]
    }
  },
  "neural_network": {
    "epochs": [20, 40, 60, 80, 100],
    "metrics": {
      "loss": [2.45, 1.89, 1.52, 1.31, 1.25],
      "val_loss": [2.51, 1.95, 1.58, 1.35, 1.31]
    }
  }
}
```

---

### 3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ

#### –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å checkpoints:

```python
from src.training import BPMTrainer, CheckpointManager

# –°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ checkpoints
checkpoint_manager = CheckpointManager("models/bpm_correctors/checkpoints")

# –û–±—É—á–µ–Ω–∏–µ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ checkpoints
trainer = BPMTrainer("test_data_2000.txt")
trainer.run_full_training_pipeline(
    algorithms=['xgboost', 'neural_network'],
    save_dir='models/bpm_correctors',
    checkpoint_manager=checkpoint_manager,  # ‚Üê –≤–∫–ª—é—á–∏—Ç—å checkpoints
    checkpoint_frequency=20  # —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ 20 –∏—Ç–µ—Ä–∞—Ü–∏–π/—ç–ø–æ—Ö
)
```

#### –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è:

```python
from src.training import BPMTrainer, CheckpointManager, TrainingResumer

# –ú–µ–Ω–µ–¥–∂–µ—Ä –∏ resumer
checkpoint_manager = CheckpointManager("models/bpm_correctors/checkpoints")
resumer = TrainingResumer(checkpoint_manager)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
if resumer.can_resume('xgboost'):
    print("–ù–∞–π–¥–µ–Ω checkpoint, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")

    trainer = BPMTrainer("test_data_2000.txt")

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    trainer.run_full_training_pipeline(
        algorithms=['xgboost'],
        resume=True,  # ‚Üê –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ checkpoint
        checkpoint_manager=checkpoint_manager
    )
else:
    print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è...")
```

#### –†—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ checkpoints:

```python
from src.training.models import XGBoostBPMModel

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ checkpoint
model = XGBoostBPMModel()
checkpoint_manager.load_checkpoint(
    "models/.../xgboost_epoch_200.pkl",
    model
)

# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
model.train(X_train, y_train, X_val, y_val, n_estimators=100)  # –µ—â–µ 100 –¥–µ—Ä–µ–≤—å–µ–≤

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ checkpoint
checkpoint_manager.save_checkpoint(
    model, epoch=300,
    metrics={'val_mae': 1.8},
    algorithm='xgboost'
)
```

#### –ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏:

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä checkpoint —Å –ª—É—á—à–µ–π –º–µ—Ç—Ä–∏–∫–æ–π
best_checkpoint = checkpoint_manager.get_best_checkpoint(
    algorithm='neural_network',
    metric='val_loss'  # –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å val_loss
)

if best_checkpoint:
    model = NeuralBPMModel()
    checkpoint_manager.load_checkpoint(best_checkpoint['model_path'], model)
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å: val_loss={best_checkpoint['metrics']['val_loss']:.3f}")
```

---

### 4. CLI –ø–æ–¥–¥–µ—Ä–∂–∫–∞

#### –û–±—É—á–µ–Ω–∏–µ —Å checkpoints:

```bash
# –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç checkpoints)
python scripts/train_bpm_corrector.py data.txt \
    --algorithms xgboost neural_network \
    --checkpoint-dir models/checkpoints \
    --checkpoint-freq 20

# –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
python scripts/train_bpm_corrector.py data.txt \
    --resume \
    --checkpoint-dir models/checkpoints

# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ checkpoint
python scripts/train_bpm_corrector.py data.txt \
    --resume-from models/checkpoints/xgboost_epoch_200.pkl
```

#### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ checkpoints:

```bash
# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö checkpoints (–æ—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3)
python scripts/manage_checkpoints.py --cleanup \
    --checkpoint-dir models/checkpoints \
    --keep-last 3

# –ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
python scripts/manage_checkpoints.py --show-history \
    --checkpoint-dir models/checkpoints \
    --algorithm xgboost

# –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π checkpoint
python scripts/manage_checkpoints.py --best \
    --checkpoint-dir models/checkpoints \
    --algorithm neural_network \
    --metric val_loss
```

---

### 5. GUI –ø–æ–¥–¥–µ—Ä–∂–∫–∞

–í –æ–∫–Ω–µ –æ–±—É—á–µ–Ω–∏—è:

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ checkpoints:**
- ‚úÖ –í–∫–ª—é—á–µ–Ω—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
- üìÅ –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `models/bpm_correctors/checkpoints/`
- üîÑ –ß–∞—Å—Ç–æ—Ç–∞: –∫–∞–∂–¥—ã–µ 20 —ç–ø–æ—Ö/–∏—Ç–µ—Ä–∞—Ü–∏–π

**–ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**
- **Resume Training** - –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ checkpoint
- **Clear Checkpoints** - —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ checkpoint'—ã
- **View History** - –≥—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫ –ø–æ —ç–ø–æ—Ö–∞–º

**–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**
```
Training Progress:
[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë] 60/100 epochs

Last Checkpoint: epoch 60 (val_loss: 1.31)
Best Checkpoint: epoch 55 (val_loss: 1.29)

Time elapsed: 45 min
Estimated remaining: 30 min
```

---

### 6. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ Features

**–ü—Ä–æ–±–ª–µ–º–∞:** –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∏–∑ 2000 —Ç—Ä–µ–∫–æ–≤ –∑–∞–Ω–∏–º–∞–µ—Ç ~1-2 —á–∞—Å–∞.

**–†–µ—à–µ–Ω–∏–µ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ:

```python
# –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∏—á–∏
trainer.run_full_training_pipeline(...)
# –°–æ—Ö—Ä–∞–Ω—è–µ—Ç: models/.../checkpoints/features.pkl

# –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—É—Å–∫–∏ - –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑ –∫—ç—à–∞
trainer.run_full_training_pipeline(...)
# –ó–∞–≥—Ä—É–∂–∞–µ—Ç: models/.../checkpoints/features.pkl (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ!)
```

**–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞:**
```bash
rm models/bpm_correctors/checkpoints/features.pkl
```

---

### 7. –°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏ —Å–±–æ–µ

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–ª–æ—Å—å –Ω–∞ 1500-–º —Ç—Ä–µ–∫–µ –∏–∑ 2000.

```
1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π:
   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 2000/2000 —Ç—Ä–µ–∫–æ–≤ (1.5 —á–∞—Å–∞)
   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: features.pkl

2. –û–±—É—á–µ–Ω–∏–µ XGBoost:
   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 300/300 –¥–µ—Ä–µ–≤—å–µ–≤ (5 –º–∏–Ω—É—Ç)
   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: xgboost_epoch_300.pkl

3. –û–±—É—á–µ–Ω–∏–µ Neural Network:
   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60/100 —ç–ø–æ—Ö
   ‚ö†Ô∏è  –ü–†–ï–†–´–í–ê–ù–ò–ï (crash, Ctrl+C, etc.)
   ‚úÖ –ü–æ—Å–ª–µ–¥–Ω–∏–π checkpoint: neural_network_epoch_60.pkl

4. –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:
   $ python scripts/train_bpm_corrector.py data.txt --resume

   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: features.pkl (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ, –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç!)
   ‚úÖ XGBoost —É–∂–µ –æ–±—É—á–µ–Ω, –ø—Ä–æ–ø—É—â–µ–Ω
   ‚úÖ Neural Network: –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å —ç–ø–æ—Ö–∏ 61
   [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 61-100/100 —ç–ø–æ—Ö (–æ—Å—Ç–∞–ª–æ—Å—å 40%)
```

**–≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏:** 1.5 —á–∞—Å–∞ (features) + 5 –º–∏–Ω—É—Ç (XGBoost) + 36 –º–∏–Ω—É—Ç (NN 0-60) = **1 —á–∞—Å 41 –º–∏–Ω—É—Ç–∞**

---

### 8. Best Practices

#### ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:

```python
# –î–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (2000+ —Ç—Ä–µ–∫–æ–≤)
checkpoint_frequency = 20       # –∫–∞–∂–¥—ã–µ 20 —ç–ø–æ—Ö
keep_last_checkpoints = 5       # —Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
auto_cleanup = True             # –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö

# –î–ª—è –±—ã—Å—Ç—Ä—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (100-500 —Ç—Ä–µ–∫–æ–≤)
checkpoint_frequency = 50       # —Ä–µ–∂–µ
keep_last_checkpoints = 2       # –º–µ–Ω—å—à–µ –º–µ—Å—Ç–∞
```

#### ‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ:

- **Checkpoint'—ã –∑–∞–Ω–∏–º–∞—é—Ç –º–µ—Å—Ç–æ:** ~50-100 MB –∫–∞–∂–¥—ã–π
- **Features.pkl:** ~500 MB –¥–ª—è 2000 —Ç—Ä–µ–∫–æ–≤
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:** –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö checkpoint'–æ–≤

#### üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–µ—Å—Ç–∞:

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
checkpoint_manager.cleanup_old_checkpoints(
    algorithm='xgboost',
    keep_last=1  # –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
)
```

---

### 9. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ real-time

GUI –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç:

```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Neural Network Training - Epoch 65/100

Current Metrics:
  Train Loss: 1.24
  Val Loss:   1.31  ‚Üê –ª—É—á—à–∞—è: 1.29 (epoch 55)

Checkpoints:
  ‚úÖ Last saved: epoch 60 (5 epochs ago)
  ‚è∞ Next save:  epoch 80 (15 epochs)

Memory:
  Checkpoint size: 85.2 MB
  Total checkpoints: 187.5 MB (3 saved)
  Features cache: 523.1 MB
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

### 10. Troubleshooting

**Q: Checkpoint –Ω–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è?**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
ls -la models/bpm_correctors/checkpoints/

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
df -h
```

**Q: –ù–µ –Ω–∞—Ö–æ–¥–∏—Ç checkpoint –¥–ª—è resume?**
```python
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ
checkpoint_manager.get_latest_checkpoint('xgboost')
# –ï—Å–ª–∏ None - checkpoint'–æ–≤ –Ω–µ—Ç
```

**Q: –ö–∞–∫ —É–¥–∞–ª–∏—Ç—å –≤—Å–µ checkpoint'—ã?**
```bash
rm -rf models/bpm_correctors/checkpoints/*
```

**Q: Features.pkl —É—Å—Ç–∞—Ä–µ–ª (–∏–∑–º–µ–Ω–∏–ª–∞—Å—å feature extraction)?**
```bash
# –£–¥–∞–ª–∏—Ç—å –∫—ç—à
rm models/bpm_correctors/checkpoints/features.pkl
# –ü—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–ø—É—Å–∫–µ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ—Ç—Å—è
```

---

## –ò—Ç–æ–≥–æ

**–°—Ö–µ–º–∞ checkpoint'–æ–≤ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:**

‚úÖ **–ó–∞—â–∏—Ç–∞ –æ—Ç –ø–æ—Ç–µ—Ä–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞** - –º–æ–∂–Ω–æ –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç
‚úÖ **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏—á–µ–π** - –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞—Ç—å 1-2 —á–∞—Å–∞ —Ä–∞–±–æ—Ç—ã
‚úÖ **–í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
‚úÖ **–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è** - –≥—Ä–∞—Ñ–∏–∫–∏ –∏ JSON
‚úÖ **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é** - –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö checkpoint'–æ–≤
‚úÖ **CLI & GUI** - –ø–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ –æ–±–æ–∏—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞—Ö

**–î–ª—è 2000+ —Ç—Ä–µ–∫–æ–≤ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ!** üöÄ
